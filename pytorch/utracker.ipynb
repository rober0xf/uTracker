{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12603678,"sourceType":"datasetVersion","datasetId":7961015}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn import BCEWithLogitsLoss\nfrom sklearn.model_selection import train_test_split\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ufc-dataset/ufc-master.csv\")\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_df = df.dropna(subset=['Winner']) \nclean_df.shape ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_df[\"target\"] = df[\"Winner\"].map({\"Red\": 1.0, \"Blue\": 0.0})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clean_df[\"target\"])\nprint(clean_df[\"Winner\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_drop = [\"Location\", \"Country\", \"LoseStreakDif\", \"WinStreakDif\", \"LongestWinStreakDif\", \"WinDif\", \"LossDif\", \"TotalRoundDif\", \n                \"TotalTitleBoutDif\", \"KODif\", \"SubDif\", \"AvgSubAttDif\", \"AvgTDDif\", \"EmptyArena\", \"BKOOdds\", \"RKOOdds\", \"BMatchWCRank\",\n                'RMatchWCRank', 'RWFlyweightRank', 'RWFeatherweightRank', 'RWStrawweightRank', 'RWBantamweightRank', 'RHeavyweightRank', \n                'RLightHeavyweightRank', 'RMiddleweightRank', 'RWelterweightRank', 'RLightweightRank', 'RFeatherweightRank', 'RBantamweightRank', \n                'RFlyweightRank', 'RPFPRank', 'BWFlyweightRank', 'BWFeatherweightRank', 'BWStrawweightRank', 'BWBantamweightRank',\n                'BHeavyweightRank', 'BLightHeavyweightRank', 'BMiddleweightRank', 'BWelterweightRank', 'BLightweightRank', 'BFeatherweightRank',\n                'BBantamweightRank', 'BFlyweightRank', 'BPFPRank', 'BetterRank', 'RedDecOdds', 'BlueDecOdds', 'RSubOdds', 'BSubOdds'\n                ,'Date','Finish','FinishDetails','FinishRound','FinishRoundTime', 'RedFighter', 'BlueFighter', 'Winner']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_df = clean_df.drop(cols_to_drop, axis=1, errors='ignore')  # safe drop","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(clean_df.shape)\nprint(clean_df[\"target\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols = clean_df.select_dtypes(include=['float64','int64']).columns\nclean_df[numeric_cols] = clean_df[numeric_cols].fillna(clean_df[numeric_cols].median())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(numeric_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols = clean_df.select_dtypes(include=['object']).columns\nclean_df[categorical_cols] = clean_df[categorical_cols].fillna(\"Unknown\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(categorical_cols)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_cols = [\"WeightClass\", \"Gender\", \"BlueStance\", \"RedStance\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_df = pd.get_dummies(clean_df, columns=categorical_cols, drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clean_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FightersDataset(Dataset):\n    def __init__(self, dataframe, label_col=\"target\"):\n        df = dataframe.copy()\n        self.X = df.drop(label_col, axis=1).fillna(0).astype(\"float32\").values\n        self.y = df[label_col].values.astype(\"float32\")\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.X[idx])\n        y = torch.tensor(self.y[idx])\n        return x, y","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = FightersDataset(clean_df)\nprint(len(dataset))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, val_df = train_test_split(clean_df, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# we need to use this to train\navailable_features = [\n    'BlueAvgSigStrLanded', 'BlueAvgSigStrPct', 'BlueAvgSubAtt', \n    'BlueAvgTDLanded', 'BlueAvgTDPct', 'BlueWinsByKO', 'BlueWinsBySubmission',\n    'RedAvgSigStrLanded', 'RedAvgSigStrPct', 'RedAvgSubAtt',\n    'RedAvgTDLanded', 'RedAvgTDPct', 'RedWinsByKO', 'RedWinsBySubmission'\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train_df[available_features].values\ny = train_df['target'].values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\nval_ds = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_ds = FightersDataset(train_df, label_col=\"target\")\n# val_ds = FightersDataset(val_df, label_col=\"target\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=64)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FightPredictor(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = FightPredictor(input_dim=train_df.drop(columns=[\"target\"]).shape[1])\nmodel = FightPredictor(input_dim=14)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(60):\n    model.train()\n    for X, y in train_loader:\n        optimizer.zero_grad()\n        preds = model(X).squeeze(1)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}: loss={loss.item():.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.nn.functional import sigmoid\n\nmodel.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for X, y in val_loader:\n        preds = sigmoid(model(X)).squeeze(1)\n        pred_labels = (preds > 0.5).float()\n        correct += (pred_labels == y).sum().item()\n        total += y.size(0)\n\nprint(\"Validation accuracy:\", correct / total)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_df.shape)\nprint(X_train.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"save_dir = \"/kaggle/working\"\ntorch.save({\"model_state_dict\": model.state_dict()}, os.path.join(save_dir, \"predictor.pt\"))\nmetadata = {\n    \"input_dim\": len(available_features),\n    \"feature_names\": available_features\n}\nwith open(os.path.join(save_dir, \"predictor_meta.json\"), \"w\") as f:\n    json.dump(metadata, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}